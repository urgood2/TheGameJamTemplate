# Implementation Plan: End-to-End Game Testing System (Playwright-like)

## 1) Executive Summary (TL;DR)
Build a deterministic “test mode” runtime in the C++ engine that can (a) run headless/offscreen, (b) consume scripted input events, (c) expose a `test_harness` Lua API for driving and observing the game, and (d) produce CI-friendly reports and screenshot diffs. On top of that, implement a Lua test framework (`describe/it`, assertions, discovery, reporters) plus baseline screenshot management and a GitHub Actions workflow with artifact uploads for failures.

---

## 2) Architecture Overview

### 2.1 Runtime components
- **C++ Test Mode Core**
  - Parses flags (`--test-mode`, `--headless`, `--test-script`, etc.)
  - Forces determinism (fixed timestep, seeded RNG, controlled vsync)
  - Boots Lua, registers `test_harness`, runs an entry script
  - Controls exit codes and report output

- **C++ Test Input Provider**
  - Replaces/overrides the normal input backend when `--test-mode`
  - Reads a per-frame “scheduled event queue” generated by Lua calls
  - Applies key/mouse state updates at frame boundaries

- **C++ Verification Services**
  - **Screenshot capture** to PNG on demand
  - **Screenshot diff** against baseline (thresholded) producing diff artifacts
  - **Log capture** (ring buffer) and pattern assertions

- **Lua Test Framework**
  - `describe()` / `it()` with hooks (`before_each`, `after_each`)
  - Assertions for state, logs, and screenshots
  - Test discovery across `assets/scripts/tests/e2e/*.lua`
  - Reporters: JSON (CI), TAP (human/CI), plus console summary

### 2.2 Data flow (per test)
1. Game starts with `--test-mode` → engine initializes deterministically.
2. Engine loads Lua entrypoint `assets/scripts/tests/framework/bootstrap.lua`.
3. Lua runner discovers tests, executes each `it()` body sequentially.
4. Test code calls `test_harness.*` (input, waits, screenshot, state/log queries).
5. Engine executes frames, applies queued input events, captures screenshots, logs.
6. Runner asserts and reports results; engine exits with 0/1 and writes report JSON.

---

## 3) Phase Breakdown (numbered tasks with dependencies, acceptance criteria, complexity)

### Phase 0 — Contracts & Scaffolding (required to parallelize)
**Goal:** Freeze interfaces so multiple agents can implement in parallel.

**0.1 Define test-mode config + CLI contract (Complexity: S)**
- **Files (new):**
  - `src/testing/test_mode_config.hpp`
- **Files (modify, integration points):**
  - `src/main.cpp` (or the game entrypoint file where argv is parsed)
- **Implementation:**
  - Define `struct TestModeConfig { bool enabled; bool headless; uint32_t seed; uint32_t fixed_fps; int width; int height; std::string test_entry; std::string suite_dir; std::string report_path; std::string artifacts_dir; bool update_baselines; bool fail_on_missing_baseline; }`
  - Decide canonical flags:
    - `--test-mode`
    - `--headless`
    - `--seed <u32>` (default fixed, e.g. 12345)
    - `--fixed-fps <int>` (default 60)
    - `--resolution <WxH>` (default 1280x720)
    - `--test-script <path>` (single file)
    - `--test-suite <dir>` (discovery mode)
    - `--report <path>` (default `tests/out/report.json`)
    - `--artifacts <dir>` (default `tests/out/artifacts/`)
    - `--update-baselines`
    - `--fail-on-missing-baseline` (default true)
- **Depends on:** none
- **Acceptance criteria:**
  - Flags parse cleanly; unknown flags produce a clear error + nonzero exit.
  - `TestModeConfig` is accessible to the engine init path.

**0.2 Define Lua `test_harness` API contract (Complexity: S)**
- **Files (new):**
  - `assets/scripts/tests/framework/test_harness_contract.lua` (documents expected functions + argument types)
- **Implementation (API surface):**
  - Input:
    - `test_harness.press_key(keycode)`
    - `test_harness.release_key(keycode)`
    - `test_harness.type_text(text)` (optional; can map to per-char key events later)
    - `test_harness.move_mouse(x, y)`
    - `test_harness.mouse_down(button)` / `mouse_up(button)`
    - `test_harness.click(x, y, button?)`
  - Timing:
    - `test_harness.wait_frames(n)`
    - `test_harness.wait_until(fn, timeout_frames, poll_every_frames?)`
  - Observability:
    - `test_harness.get_state(path)` (Lua global traversal)
    - `test_harness.get_log()` / `test_harness.find_log(pattern, since_index?)`
  - Screenshots:
    - `test_harness.screenshot(path)`
    - `test_harness.assert_screenshot(baseline_path, options_table)`
  - Process control:
    - `test_harness.exit(code)`
    - `test_harness.now_frame()` (optional)
- **Depends on:** none
- **Acceptance criteria:**
  - Contract explicitly defines failure behavior (error vs `nil, err`), default timeouts, and path conventions.

---

### Phase 1 — Test Mode Infrastructure (C++ engine)
**Goal:** Deterministic test mode + headless/offscreen + Lua bindings.

**1.1 Implement `--test-mode` plumbing and deterministic loop (Complexity: L)**
- **Files (new):**
  - `src/testing/test_mode.hpp`
  - `src/testing/test_mode.cpp`
- **Files (modify):**
  - `src/main.cpp` (or entrypoint)
  - `src/engine/game_loop.cpp` (or equivalent)
- **Implementation:**
  - Add `class TestModeController` with:
    - `void ApplyDeterminism(const TestModeConfig&)` (seed RNG, fixed timestep, disable vsync if applicable)
    - `bool IsEnabled() const`
  - Force fixed timestep in test mode: e.g. `dt = 1.0f / fixed_fps`.
  - Add frame counter `uint64_t test_frame_index` stored centrally.
- **Depends on:** 0.1
- **Acceptance criteria:**
  - Running with `--test-mode --fixed-fps 60 --seed 1` produces stable frame stepping (no real-time drift).
  - Engine exposes a monotonically increasing test frame index.

**1.2 Implement `--headless` offscreen rendering path (Complexity: L)**
- **Files (new):**
  - `src/testing/headless_surface.hpp`
  - `src/testing/headless_surface.cpp`
- **Files (modify):**
  - `src/render/renderer.cpp` (or equivalent renderer init)
  - `src/platform/window.cpp` (or equivalent)
- **Implementation:**
  - If the engine can render without a window, create an offscreen framebuffer target (FBO/texture) sized from `--resolution`.
  - If the engine *requires* a window/context, implement a “hidden window” fallback and document CI requirement (e.g., Xvfb on Linux).
  - Ensure `screenshot()` reads from the final composited framebuffer used in headless.
- **Depends on:** 0.1, 1.1
- **Acceptance criteria:**
  - `--headless` runs without user interaction and can still capture screenshots.
  - If headless is unsupported on a platform, it fails fast with a clear message and nonzero exit.

**1.3 Add `TestInputProvider` that overrides normal input (Complexity: M)**
- **Files (new):**
  - `src/testing/test_input_provider.hpp`
  - `src/testing/test_input_provider.cpp`
- **Files (modify):**
  - `src/input/input_system.cpp` (or equivalent)
- **Data structures:**
  - `enum class TestEventType { KeyDown, KeyUp, MouseMove, MouseDown, MouseUp }`
  - `struct TestInputEvent { TestEventType type; uint64_t apply_frame; int a; int b; int c; }` (interpret a/b/c by type)
  - `class TestEventQueue { void Enqueue(...); void DrainForFrame(uint64_t frame, std::vector<TestInputEvent>& out); }`
- **Depends on:** 1.1
- **Acceptance criteria:**
  - Key down/up and mouse move/click events affect the game exactly on the requested frame.
  - Invalid keycodes/buttons are rejected with a Lua-visible error.

**1.4 Expose `test_harness` global to Lua (Complexity: L)**
- **Files (new):**
  - `src/testing/test_harness_lua.hpp`
  - `src/testing/test_harness_lua.cpp`
- **Files (modify):**
  - `src/lua/lua_bindings.cpp` (or equivalent binding registry)
- **Implementation:**
  - Register a Lua table `test_harness` with C functions:
    - `press_key`, `release_key`, `move_mouse`, `mouse_down`, `mouse_up`, `click`
    - `wait_frames` (implemented as yielding/cooperating with engine loop; see 2.2/engine integration note)
    - `screenshot`
    - `get_state`
    - `exit`
  - Provide consistent error strategy: Lua error for programmer mistakes; `nil, err` for runtime failures (file IO, missing baseline, etc.).
- **Depends on:** 0.2, 1.1, 1.3
- **Acceptance criteria:**
  - A minimal Lua script can press a key, wait frames, take a screenshot, and exit 0.

**1.5 Add screenshot capture API (Complexity: M)**
- **Files (new):**
  - `src/testing/screenshot_capture.hpp`
  - `src/testing/screenshot_capture.cpp`
- **Implementation:**
  - `bool CaptureScreenshotPng(const std::string& path, std::string* err)`
  - Create directories as needed under `--artifacts` and/or within project `tests/`.
  - Sanitize paths to prevent writing outside allowed output roots (reject `..` segments unless explicitly allowed).
- **Depends on:** 1.2, 1.4
- **Acceptance criteria:**
  - `test_harness.screenshot("tests/out/artifacts/foo.png")` produces a valid PNG at the expected resolution.

---

### Phase 2 — Lua Test Framework
**Goal:** Test DSL, discovery, robust timeouts, CI output.

**2.1 Create core runner + suite model (Complexity: M)**
- **Files (new):**
  - `assets/scripts/tests/framework/test_runner.lua`
- **Data structures (Lua):**
  - `Suite = { name, children, tests, before_each, after_each }`
  - `TestCase = { name, fn, file, line, tags }`
  - `Result = { status="passed|failed|skipped", error, duration_frames, artifacts={} }`
- **Implementation:**
  - `describe(name, fn)` pushes suite stack; `it(name, fn)` registers test.
  - Add `before_each(fn)` / `after_each(fn)` hooks (scoped to current suite).
  - Provide `t.run(opts)` which executes tests sequentially with per-test isolation hook calls.
- **Depends on:** 0.2 (API contract)
- **Acceptance criteria:**
  - A sample test file can define multiple `it()` blocks and runner executes all with a pass/fail summary.

**2.2 Implement waiting + timeouts + failure propagation (Complexity: M)**
- **Files (modify):**
  - `assets/scripts/tests/framework/test_runner.lua`
- **Implementation:**
  - Provide `t.wait_frames(n)` wrapper calling `test_harness.wait_frames(n)`.
  - Provide `t.wait_until(predicate, timeout_frames, poll_every_frames)` using `test_harness.wait_until` if available; otherwise implement polling loop with `wait_frames`.
  - Enforce default timeouts (e.g., 600 frames = 10s @60fps) and fail tests with clear errors.
- **Depends on:** 1.4 (or at least the planned semantics)
- **Acceptance criteria:**
  - Hung predicates time out deterministically and mark the test failed (not stuck process).

**2.3 Assertions and matchers (Complexity: M)**
- **Files (new):**
  - `assets/scripts/tests/framework/assertions.lua`
  - `assets/scripts/tests/framework/matchers.lua`
- **Implementation:**
  - `assert_eq(actual, expected, msg?)`
  - `assert_true(value, msg?)`
  - `assert_state(path, expected, opts?)` uses `test_harness.get_state(path)`
  - `assert_log_contains(pattern, opts?)` uses `test_harness.find_log`
  - `assert_screenshot(baseline, opts?)` delegates to `test_harness.assert_screenshot` (Phase 3) or does capture+compare via harness calls.
- **Depends on:** 1.4
- **Acceptance criteria:**
  - Assertion failures include file/test name, message, and relevant diff (expected/actual) when possible.

**2.4 Test discovery (Complexity: S)**
- **Files (new):**
  - `assets/scripts/tests/framework/discovery.lua`
  - `assets/scripts/tests/framework/bootstrap.lua`
- **Implementation:**
  - If `--test-script` is provided: load that file only.
  - If `--test-suite` is provided: enumerate `*.lua` under the suite dir.
  - If Lua lacks filesystem enumeration, add a C++ helper `test_harness.list_files(dir, glob)` (planned in Phase 1.4 extension) or do discovery in C++ and pass list via `test_harness.args`.
- **Depends on:** 0.1, 1.4
- **Acceptance criteria:**
  - `--test-suite assets/scripts/tests/e2e` runs every `*.lua` test file found and reports combined results.

**2.5 Reporters: JSON + TAP (Complexity: S)**
- **Files (new):**
  - `assets/scripts/tests/framework/reporters/json_reporter.lua`
  - `assets/scripts/tests/framework/reporters/tap_reporter.lua`
- **Implementation:**
  - JSON schema: `{ run_id, seed, fixed_fps, resolution, tests:[{id, name, status, duration_frames, artifacts, error}] }`
  - TAP output for console/CI: `ok/not ok` lines with diagnostics.
  - Write to `--report` path; ensure failures still flush report.
- **Depends on:** 0.1, 2.1
- **Acceptance criteria:**
  - On failure, process exit code is nonzero and report JSON exists with failure details.

---

### Phase 3 — Verification Systems (screenshots, state queries, logs, baselines)
**Goal:** Make assertions reliable and debuggable.

**3.1 Lua state query system (C++ traversal by path) (Complexity: M)**
- **Files (new):**
  - `src/testing/lua_state_query.hpp`
  - `src/testing/lua_state_query.cpp`
- **Files (modify):**
  - `src/testing/test_harness_lua.cpp`
- **Implementation:**
  - Implement `GetLuaValueByPath(lua_State* L, const std::string& path)` supporting:
    - Dotted keys: `player.health`
    - Bracket indices: `inventory[1].name`
  - Return Lua values directly to Lua; on missing path return `nil, "missing key: ..."` (not a hard error by default).
- **Depends on:** 1.4
- **Acceptance criteria:**
  - `test_harness.get_state("some.missing")` returns `nil, err` and does not crash.
  - Nested tables and array indices work for typical paths.

**3.2 Log capture + assertions (Complexity: M)**
- **Files (new):**
  - `src/testing/test_log_capture.hpp`
  - `src/testing/test_log_capture.cpp`
- **Files (modify):**
  - `src/logging/logger.cpp` (or equivalent) to add a test sink when `--test-mode`
  - `src/testing/test_harness_lua.cpp`
- **Data structures:**
  - `struct LogLine { uint64_t frame; int level; std::string message; }`
  - Ring buffer: `std::deque<LogLine> lines; size_t capacity = 2000;`
- **Implementation:**
  - `test_harness.find_log(pattern, since_index?) -> found:boolean, index:int, line:string`
  - Optional: `test_harness.log_mark() -> index`
- **Depends on:** 1.1, 1.4
- **Acceptance criteria:**
  - Logs generated by engine/game Lua are capturable and searchable during a test.
  - Ring buffer does not grow unbounded.

**3.3 Screenshot comparison utility + diff artifacts (Complexity: M)**
- **Files (new):**
  - `src/testing/screenshot_compare.hpp`
  - `src/testing/screenshot_compare.cpp`
- **Implementation:**
  - Load baseline + actual PNG (e.g., via `stb_image.h`).
  - Compare with:
    - Per-channel absolute diff
    - Compute `max_diff`, `mean_diff`, and `pixels_over_threshold`
  - Write diff image `*_diff.png` highlighting changed pixels.
  - Options: `{ threshold, max_pixels_over, allow_size_mismatch=false }`
- **Depends on:** 1.5
- **Acceptance criteria:**
  - When images differ above threshold, comparison returns failure and produces a diff PNG in `--artifacts`.

**3.4 Baseline management workflow (Complexity: S)**
- **Files (modify):**
  - `src/testing/test_harness_lua.cpp`
  - `assets/scripts/tests/framework/matchers.lua`
- **Conventions:**
  - Baselines live in `tests/baselines/<platform>/<WxH>/...png` (platform = `linux|windows|mac` or `unknown`)
  - Actuals/diffs live in `tests/out/artifacts/<run_id>/...`
- **Implementation:**
  - `--update-baselines`: if missing baseline or mismatch, copy actual → baseline and mark test as failed or “updated” (decide and document; recommended: fail but note updated).
  - `--fail-on-missing-baseline`: if true, missing baseline fails test unless update mode is enabled.
- **Depends on:** 0.1, 3.3
- **Acceptance criteria:**
  - Missing baselines produce actionable output (where baseline expected, how to update).
  - Update mode writes baselines to the correct directory deterministically.

---

### Phase 4 — CI Integration (GitHub Actions)
**Goal:** Run tests on every push/PR with artifacts and clear summaries.

**4.1 Add workflow to build + run E2E tests (Complexity: M)**
- **Files (new):**
  - `.github/workflows/e2e-tests.yml`
- **Implementation:**
  - Steps: checkout → build game → run `./game --test-mode --headless --test-suite assets/scripts/tests/e2e --report tests/out/report.json --artifacts tests/out/artifacts`
  - Ensure headless requirements (Linux): use Xvfb if needed (`xvfb-run`) unless true offscreen.
- **Depends on:** 1.2, 2.4, 2.5
- **Acceptance criteria:**
  - Workflow fails when tests fail and uploads `tests/out/report.json` + `tests/out/artifacts/**`.

**4.2 Artifact upload for screenshot diffs and logs (Complexity: S)**
- **Files (modify):**
  - `.github/workflows/e2e-tests.yml`
- **Implementation:**
  - Upload artifacts on failure (and optionally always) with retention.
- **Depends on:** 3.3, 3.2, 4.1
- **Acceptance criteria:**
  - Failed screenshot assertions produce downloadable diff images in the CI run.

**4.3 PR-friendly test summary (Complexity: S)**
- **Files (modify/new):**
  - `.github/workflows/e2e-tests.yml`
  - Optional helper script: `scripts/ci/summarize_e2e_report.py`
- **Implementation:**
  - Parse `tests/out/report.json` and emit a concise summary to job output (and optionally PR comment).
- **Depends on:** 2.5, 4.1
- **Acceptance criteria:**
  - CI shows number of passed/failed tests and names of failed tests without needing artifact download.

**4.4 Parallel test execution (matrix) (Complexity: M)**
- **Files (modify/new):**
  - `.github/workflows/e2e-tests.yml`
  - Optional: `scripts/ci/list_e2e_tests.py` to generate matrix JSON
- **Implementation options:**
  - **Option A (simple):** hard-code a matrix list of test scripts initially.
  - **Option B (scalable):** generate matrix from repo file list at workflow runtime.
  - Each matrix job runs `--test-script <file>` and writes `tests/out/report_<name>.json`.
  - Add a final “merge reports” step/job (optional) or rely on per-job artifacts.
- **Depends on:** 0.1, 2.4, 2.5
- **Acceptance criteria:**
  - At least 2 tests run in parallel jobs; failures still upload per-test artifacts.

---

### Phase 5 — Hardening & Example Coverage
**Goal:** Reduce flakiness and provide demonstrative tests.

**5.1 Add determinism knobs for common sources of flake (Complexity: M)**
- **Files (modify):**
  - `src/testing/test_mode.cpp`
  - Any RNG entrypoints: `src/math/random.cpp` (or equivalent)
- **Implementation:**
  - Centralize RNG seed application (engine + gameplay).
  - Disable/normalize nondeterministic effects in test mode (e.g., time-based particle jitter).
- **Depends on:** 1.1
- **Acceptance criteria:**
  - Re-running the same test 10 times locally yields identical pass/fail and stable screenshots.

**5.2 Add 3 example E2E tests (menu, combat, UI) (Complexity: M)**
- **Files (new):**
  - `assets/scripts/tests/e2e/menu_test.lua`
  - `assets/scripts/tests/e2e/combat_test.lua`
  - `assets/scripts/tests/e2e/ui_test.lua`
- **Implementation:**
  - Keep tests resilient: prefer `wait_until` on state/log signals vs fixed sleeps.
  - Use screenshot asserts only at stable moments (after animations settle).
- **Depends on:** 2.1–2.3, 3.1–3.4
- **Acceptance criteria:**
  - All three tests pass headless and produce stable baseline screenshots.

**5.3 Developer ergonomics (optional but high value) (Complexity: S)**
- **Files (new):**
  - `docs/e2e_testing.md`
- **Implementation:**
  - Document how to run: visible vs headless, updating baselines, interpreting artifacts, adding new tests.
- **Depends on:** Phases 1–4
- **Acceptance criteria:**
  - A new contributor can add a test and get it running with a single command.

---

## 4) Critical Path and Dependencies
**Critical path (minimum to first green CI run):**
1. **0.1 → 1.1 → 1.4 → 2.1 → 2.5 → 4.1**
2. Add **1.2** (headless) before CI is viable unless CI can run with a visible window.
3. Add **1.5 + 3.3 + 3.4** before screenshot assertions are meaningful.

**Key dependency notes:**
- Lua framework (Phase 2) can be implemented in parallel with C++ work after **0.2** contract is frozen (using a stub/mock `test_harness` during development).
- Screenshot diff (3.3) can be developed in parallel after agreeing output paths and thresholds (0.1).

---

## 5) Parallel Execution Plan (multi-agent friendly)
- **Agent A (Engine/CLI):** 0.1, 1.1, 1.4 (core bindings), 5.1
- **Agent B (Headless/Rendering):** 1.2, 1.5 (capture integration), support for stable resolution
- **Agent C (Verification):** 3.1 (state query), 3.2 (log capture), 3.3–3.4 (image compare + baselines)
- **Agent D (Lua Framework):** 0.2, 2.1–2.5, 5.2 (example tests)
- **Agent E (CI):** 4.1–4.4, 5.3 (docs), plus scripts for matrix/list/summary

Parallelization guardrails:
- Lock the `test_harness` Lua API contract (0.2) before Agent D goes deep.
- Lock output directory conventions and report schema (2.5) before Agent E finalizes CI summaries.

---

## 6) Risk Mitigation (edge cases, failure modes, handling)
- **Rendering nondeterminism (GPU/driver/font differences):**
  - Mitigate with fixed resolution, disabled vsync, consistent shaders, and tolerant diffs (threshold + allowed pixel count).
  - Store baselines per platform + resolution: `tests/baselines/<platform>/<WxH>/`.
- **Headless support variability:**
  - Prefer true offscreen rendering; otherwise require Xvfb on Linux CI and fail fast with a clear message if unavailable.
- **Test hangs / infinite waits:**
  - Enforce timeouts in `wait_until` and per-test max frame budget; force `test_harness.exit(1)` on runaway.
- **State query fragility:**
  - Return `nil, err` for missing paths; encourage tests to assert presence explicitly before equality.
- **Input injection ordering bugs:**
  - Apply all queued events at the start of a frame; document semantics; add internal validation (e.g., no negative frames).
- **Baseline churn:**
  - Provide `--update-baselines` and always emit diff artifacts on mismatch; keep PR workflow to review baseline changes.
- **File IO failures (permissions/paths):**
  - Restrict writes to `--report` and `--artifacts` roots; validate and create directories; surface errors to Lua and JSON report.

---