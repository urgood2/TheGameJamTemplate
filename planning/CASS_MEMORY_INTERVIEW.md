# Interview Transcript: Cass Memory Update Project

**Date:** 2026-02-02
**Interviewer:** Claude (Interview Skill)
**Interviewee:** Project Owner
**Subject:** Comprehensive documentation extraction from TheGameJamTemplate for cass memory system

---

## Round 1: Project Overview & Memory System

### Q1: What is the goal?
**Answer:** Update cass memory based on the contents of this repository. Document:
- Various ways of using things
- Quirks of the code
- Lua bindings
- C++ bindings
- Common practices

All findings must be TESTED and VERIFIED, pulled from working code that produces no errors. This will enable faster, better coding and reduce agent mistakes.

### Q2: What is 'cass memory'?
**Answer:** A memory system installed on this machine - specifically the `cm` (procedural memory) system.

**Investigation revealed:**
- `cm` is a procedural memory CLI tool at `/home/ubuntu/.local/bin/cm`
- Rules are added via `cm playbook add` with categories
- Rules can be queried via `cm context "<task>" --json`

### Q3: Verification standard for patterns?
**Answer:**
- Assume C++ build succeeds
- Test & verify Lua patterns by running actual Lua code within the game context
- Ensure nothing goes wrong during execution
- Use game screenshots for analysis (raylib has screenshot capability)
- Use UI location checking, logs, and other testing methods
- Goal: 100% certainty the code works as intended

### Q4: Priority order for documentation areas?
**Answer:** Equal coverage - comprehensive scan across all subsystems.

---

## Round 2: Technical Implementation Details

### Q5: Rule organization format?
**Answer:** Individual rules via `cm playbook add` - each finding becomes a discrete rule with appropriate category.

### Q6: Binding documentation detail level?
**Answer:** Tiered by usage frequency:
- Full detail for commonly-used bindings (signature, description, all params, multiple examples, edge cases)
- Signature-only for rarely-used bindings
- **All bindings must be verified**

### Q7: Handling discovered quirks/gotchas?
**Answer:** Create separate `docs/quirks.md` file referenced from CLAUDE.md.

### Q8: Categories for cm playbook rules?
**Answer:** Mixed approach combining system + problem categories:
- Examples: `ui-gotchas`, `ecs-patterns`, `lua-bindings`, `entity-lifecycle`

### Q9: Test infrastructure approach?
**Answer:** Both permanent and temporary:
- Create permanent test scene (`assets/scripts/test/binding_tests.lua`) as ongoing regression suite
- Also use temporary verification scripts during documentation
- Copy verified patterns to cm rules

### Q10: Timeline expectation?
**Answer:** Multi-session project - plan for multiple sessions, prioritize what to scan first.

---

## Round 3: Planning & Execution Details

### Q11: What to tackle in THIS session?
**Answer:** We are NOT doing actual documentation in this session - only setting up a comprehensive plan.

### Q12: Specific pain points to prioritize?
**Answer:**
1. **UI/UIBox system** - Complex UI DSL, alignment, state tags, panel visibility
2. **Entity lifecycle** - Script initialization order, attach_ecs timing, component access

### Q13: Documentation format for planning docs?
**Answer:** Include Mermaid diagrams for flowcharts and architecture visualization.

### Q14: Plan granularity?
**Answer:** High-level phases (5-10 major phases like "Phase 1: Binding Inventory", "Phase 2: Test Infra").

### Q15: Agent parallelization?
**Answer:** Yes, design for parallel agents - break work into independent chunks that agents can tackle concurrently.

### Q16: Verification artifacts required?
**Answer:** All of the following:
- Test code (`.lua` files)
- Log output showing no errors
- Screenshots (generated by game executable via raylib's TakeScreenshot)
- References to existing working code in the repo

---

## Round 4: Final Details

### Q17: Quirks.md structure?
**Answer:** Single `docs/quirks.md` file with sections for each subsystem.

### Q18: Handling doc conflicts?
**Answer:** Code wins - trust the code, fix documentation to match actual behavior.

### Q19: Effort estimates in plan?
**Answer:** Yes, T-shirt sizes (S/M/L/XL) for each phase.

### Q20: Screenshot capture strategy?
**Answer:** Automated on test completion - test scripts call `TakeScreenshot()` at end of each test block.

### Q21: Success criteria for project completion?
**Answer:** All three must be met:
1. **Pain points resolved** - UI and entity lifecycle fully documented
2. **Coverage threshold** - 80%+ of commonly-used patterns documented with verification
3. **Test suite passing** - Permanent test scene exercises all documented patterns without errors

### Q22: External sources to incorporate?
**Answer:** No external sources - everything needed is in this repo.

---

## Summary of Key Decisions

| Decision Area | Choice |
|--------------|--------|
| Memory System | `cm playbook add` with individual rules |
| Rule Categories | Mixed (system + problem based) |
| Verification | Test code + logs + screenshots + code refs |
| Quirks Location | `docs/quirks.md` (single file) |
| Plan Granularity | High-level phases with T-shirt sizing |
| Parallelization | Yes, design for multiple concurrent agents |
| Priority Pain Points | UI/UIBox system, Entity lifecycle |
| Doc Format | Markdown with Mermaid diagrams |
| Success Criteria | Pain points + 80% coverage + passing tests |
| Timeline | Multi-session project |
